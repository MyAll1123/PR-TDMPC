import os
import sys
import time

# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥æ”¯æŒä¸åŒå¹³å°çš„æ¸²æŸ“
if sys.platform != "darwin":  # å¦‚æœä¸æ˜¯ macOS å¹³å°
    os.environ["MUJOCO_GL"] = "egl"  # ä½¿ç”¨ EGL æ¸²æŸ“ï¼ˆé€‚ç”¨äº Linuxï¼‰

os.environ["LAZY_LEGACY_OP"] = "0"  # ç¦ç”¨ PyTorch çš„æ‡’æƒ°æ“ä½œï¼ˆå¯èƒ½ä¸æ€§èƒ½ä¼˜åŒ–æœ‰å…³ï¼‰

import warnings

# å¿½ç•¥æ‰€æœ‰è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore")

import torch
import hydra  # ç”¨äºé…ç½®ç®¡ç†
from termcolor import colored  # ç”¨äºæ‰“å°å¸¦é¢œè‰²çš„æ–‡æœ¬

# å¯¼å…¥é¡¹ç›®ä¸­çš„æ¨¡å—
from .common.parser import parse_cfg, TASK_SET  # é…ç½®è§£æå™¨
from .common.seed import set_seed  # éšæœºç§å­è®¾ç½®
from .envs import make_env  # ç¯å¢ƒåˆ›å»ºå‡½æ•°
from .tdmpc2 import TDMPC2  # TD-MPC2 ç®—æ³•å®ç°
from .common.buffer import Buffer  # ç»éªŒå›æ”¾ç¼“å†²åŒº
from .common.logger import Logger  # æ—¥å¿—è®°å½•å™¨
from .trainer.offline_trainer import OfflineTrainer  # ç¦»çº¿è®­ç»ƒå™¨
from .trainer.online_trainer import OnlineTrainer  # åœ¨çº¿è®­ç»ƒå™¨

# å¯¼å…¥é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨
try:
    from .trainer.integrated_preference_trainer import IntegratedPreferenceTrainer
    INTEGRATED_PREFERENCE_AVAILABLE = True
    print(colored("ğŸš€ é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨å¯ç”¨ - åŒè·¯å¾„ç‰ˆæœ¬", "green", attrs=["bold"]))
except ImportError as e:
    INTEGRATED_PREFERENCE_AVAILABLE = False
    print(colored(f"âš ï¸ é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨ä¸å¯ç”¨: {e}", "yellow"))
    print(colored("å°†ä½¿ç”¨æ ‡å‡†è®­ç»ƒå™¨", "yellow"))

# å¯¼å…¥ä¼˜å…ˆçº§åå¥½é›†æˆå™¨
try:
    # æ·»åŠ é¡¹ç›®æ ¹è·¯å¾„åˆ°sys.pathä»¥æ”¯æŒç»å¯¹å¯¼å…¥
    import sys
    import os
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
    if project_root not in sys.path:
        sys.path.insert(0, project_root)
    
    from prm.prioritized_preference_integrator import (
        PrioritizedPreferenceIntegrator,
        IntegrationConfig,
        create_prioritized_preference_integrator
    )
    PRIORITIZED_PREFERENCE_AVAILABLE = True
    print(colored("ğŸ¯ ä¼˜å…ˆçº§åå¥½é›†æˆå™¨å¯ç”¨ - ç»éªŒå›æ”¾ç‰ˆæœ¬", "magenta", attrs=["bold"]))
except ImportError as e:
    PRIORITIZED_PREFERENCE_AVAILABLE = False
    print(colored(f"âš ï¸ ä¼˜å…ˆçº§åå¥½é›†æˆå™¨ä¸å¯ç”¨: {e}", "yellow"))
    print(colored("å°†ä½¿ç”¨æ ‡å‡†åå¥½ç³»ç»Ÿ", "yellow"))

# å¯ç”¨ CuDNN çš„åŸºå‡†æ¨¡å¼ä»¥ä¼˜åŒ–æ€§èƒ½ï¼ˆé€‚ç”¨äºå›ºå®šå¤§å°çš„è¾“å…¥ï¼‰
torch.backends.cudnn.benchmark = True


@hydra.main(config_name="config", config_path=".")
def train(cfg: dict):
    """è®­ç»ƒè„šæœ¬"""
    # ç¡®ä¿è®­ç»ƒæ­¥æ•°å¤§äº 0
    assert cfg.steps > 0, "Must train for at least 1 step."

    # 5. å¤šä»»åŠ¡ç›¸å…³å‚æ•°
    cfg.multitask = cfg.task in TASK_SET.keys()  # æ˜¯å¦ä¸ºå¤šä»»åŠ¡
    if cfg.multitask:
        cfg.task_title = cfg.task.upper()  # å¤šä»»åŠ¡æ ‡é¢˜å¤§å†™
        # é’ˆå¯¹ mt80 ä»»åŠ¡å’Œéƒ¨åˆ†æ¨¡å‹è§„æ¨¡çš„ task_dim ç‰¹æ®Šå¤„ç†
        cfg.task_dim = 96 if cfg.task == "mt80" or cfg.model_size in {1, 317} else 64
    else:
        cfg.task_dim = 0  # å•ä»»åŠ¡æ—¶ task_dim è®¾ä¸º 0
    # ä»»åŠ¡åˆ—è¡¨ï¼šå¤šä»»åŠ¡ä¸ºä»»åŠ¡é›†ï¼Œå•ä»»åŠ¡ä¸ºè‡ªèº«
    cfg.tasks = TASK_SET.get(cfg.task, [cfg.task])

    # åˆ›å»ºç¯å¢ƒ
    env = make_env(cfg)

    # è§£æé…ç½®æ–‡ä»¶
    cfg = parse_cfg(cfg, env)

    # è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§
    set_seed(cfg.seed)

    # æ‰“å°å·¥ä½œç›®å½•
    print(colored("Work dir:", "yellow", attrs=["bold"]), cfg.work_dir)

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨åå¥½å¼•æ“
    use_preference_engine = getattr(cfg, "use_preference_engine", False)
    preference_enabled = getattr(cfg, "preference_enabled", False)
    
    # æ£€æŸ¥å†å²æ•°æ®æ”¶é›†å’Œåå¥½æ¨¡å‹åˆ›å»ºé…ç½®
    history_enabled = getattr(cfg, "history_data_collection", {}).get("enabled", False)
    preference_model_enabled = getattr(cfg, "preference_model_creation", {}).get("enabled", False)
    
    # æ£€æŸ¥ä¼˜å…ˆçº§ç»éªŒå›æ”¾é…ç½®
    prioritized_replay_enabled = getattr(cfg, "prioritized_experience_replay", {}).get("enabled", False)
    
    print(colored(f"åå¥½å¼•æ“çŠ¶æ€: {'å¯ç”¨' if use_preference_engine else 'ç¦ç”¨'}", "yellow", attrs=["bold"]))
    print(colored(f"åå¥½å­¦ä¹ æ€»å¼€å…³: {'å¯ç”¨' if preference_enabled else 'ç¦ç”¨'}", "yellow", attrs=["bold"]))
    print(colored(f"å†å²æ•°æ®æ”¶é›†: {'å¯ç”¨' if history_enabled else 'ç¦ç”¨'}", "yellow", attrs=["bold"]))
    print(colored(f"åå¥½æ¨¡å‹åˆ›å»º: {'å¯ç”¨' if preference_model_enabled else 'ç¦ç”¨'}", "yellow", attrs=["bold"]))
    print(colored(f"ä¼˜å…ˆçº§ç»éªŒå›æ”¾: {'å¯ç”¨' if prioritized_replay_enabled else 'ç¦ç”¨'}", "magenta", attrs=["bold"]))
    
    # ä¼˜å…ˆä½¿ç”¨ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿï¼Œå…¶æ¬¡ä½¿ç”¨é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨
    should_use_prioritized_preference = (
        PRIORITIZED_PREFERENCE_AVAILABLE and
        prioritized_replay_enabled and
        not cfg.multitask  # ä»…å•ä»»åŠ¡æ”¯æŒ
    )
    
    should_use_integrated_preference = False  # ç¦ç”¨åŸå§‹é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨
    
    print(colored(f"ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿ: {'å¯ç”¨' if should_use_prioritized_preference else 'ç¦ç”¨'}", "magenta", attrs=["bold"]))
    print(colored(f"é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨: {'å¯ç”¨' if should_use_integrated_preference else 'ç¦ç”¨'}", "cyan", attrs=["bold"]))
    
    # æ ¹æ®é…ç½®é€‰æ‹©è®­ç»ƒå™¨ç±» - ä¼˜å…ˆçº§ç³»ç»Ÿ > é›†æˆåå¥½å­¦ä¹  > æ ‡å‡†è®­ç»ƒå™¨
    if cfg.multitask:
        trainer_cls = OfflineTrainer
        print(colored("ğŸ“‹ ä½¿ç”¨ç¦»çº¿è®­ç»ƒå™¨ (å¤šä»»åŠ¡)", "blue", attrs=["bold"]))
    elif should_use_prioritized_preference:
        trainer_cls = IntegratedPreferenceTrainer  # å¤ç”¨é›†æˆè®­ç»ƒå™¨ï¼Œä½†æ·»åŠ ä¼˜å…ˆçº§ç³»ç»Ÿ
        print(colored("ğŸ¯ ä½¿ç”¨ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿ - ç»éªŒå›æ”¾ç‰ˆæœ¬", "magenta", attrs=["bold"]))
        print(colored("   âœ… ä¼˜å…ˆçº§ç»éªŒå›æ”¾ç¼“å†²æ± ", "magenta"))
        print(colored("   âœ… ç½®ä¿¡åº¦ + æ—¶é—´ä¼˜å…ˆçº§", "magenta"))
        print(colored("   âœ… åŸºäºæŸå¤±çš„ä¼˜å…ˆçº§æ›´æ–°", "magenta"))
        print(colored("   âœ… TD-MPC2 + åå¥½å¥–åŠ±ç»“åˆ", "green"))
    elif should_use_integrated_preference:
        trainer_cls = IntegratedPreferenceTrainer
        print(colored("ğŸš€ ä½¿ç”¨é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨ - åŒè·¯å¾„ç‰ˆæœ¬", "green", attrs=["bold"]))
        print(colored("   âœ… TD-MPC2 + åå¥½å¥–åŠ±ç»“åˆ", "green"))
        print(colored("   âœ… å†…å­˜ç¼“å­˜ç³»ç»Ÿ", "green"))
        print(colored("   âœ… é›¶æ–‡ä»¶IOæ“ä½œ", "green"))
    else:
        trainer_cls = OnlineTrainer
        print(colored("ğŸ“ ä½¿ç”¨æ ‡å‡†åœ¨çº¿è®­ç»ƒå™¨ (é™çº§)", "yellow", attrs=["bold"]))

    # åˆå§‹åŒ–è®­ç»ƒå™¨
    if cfg.multitask:
        # ç¦»çº¿è®­ç»ƒå™¨ï¼ˆå¤šä»»åŠ¡ï¼‰
        trainer = trainer_cls(
            cfg=cfg,
            env=env,
            agent=TDMPC2(cfg),
            buffer=Buffer(cfg),
            logger=Logger(cfg)
        )
    elif should_use_prioritized_preference:
        # ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿè®­ç»ƒå™¨ï¼ˆå•ä»»åŠ¡ï¼‰
        print(colored("åˆå§‹åŒ–ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿ...", "magenta"))
        
        # åˆ›å»ºä¼˜å…ˆçº§åå¥½é›†æˆå™¨é…ç½®
        integration_config = IntegrationConfig(
            enable_prioritized_replay=True,
            enable_legacy_compatibility=True,
            enable_performance_monitoring=True,
            integration_mode="prioritized_only",  # ä¼˜å…ˆä½¿ç”¨ä¼˜å…ˆçº§ç³»ç»Ÿ
            max_memory_usage_mb=getattr(cfg, 'max_memory_usage_mb', 2048.0),
            performance_check_interval=getattr(cfg, 'performance_check_interval', 100),
            fallback_to_legacy=True,
            prioritized_weight=0.8,
            legacy_weight=0.2
        )
        
        # å¯¼å…¥åå¥½æ„ŸçŸ¥TD-MPC2
        try:
            from prm.preference_aware_tdmpc2 import create_preference_aware_tdmpc2
            from prm.hybrid_value_estimator import HybridValueConfig
            
            # åˆ›å»ºåå¥½æ„ŸçŸ¥æ™ºèƒ½ä½“
            print(colored("åˆ›å»ºåå¥½æ„ŸçŸ¥TD-MPC2æ™ºèƒ½ä½“...", "cyan"))
            agent = create_preference_aware_tdmpc2(
                cfg=cfg,
                preference_integrator=None,  # åˆå§‹ä¸ºNoneï¼Œåç»­ç”±è®­ç»ƒå™¨ç®¡ç†
                preference_trainer=None,  # åˆå§‹ä¸ºNoneï¼Œåç»­ç”±è®­ç»ƒå™¨ç®¡ç†
                hybrid_config=HybridValueConfig.from_config(cfg),
                enable_preference_planning=True
            )
            print(colored("âœ… åå¥½æ„ŸçŸ¥TD-MPC2æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ", "cyan"))
            
        except ImportError as e:
            print(colored(f"âš ï¸ æ— æ³•å¯¼å…¥åå¥½æ„ŸçŸ¥TD-MPC2ï¼Œä½¿ç”¨æ ‡å‡†æ™ºèƒ½ä½“: {e}", "yellow"))
            agent = TDMPC2(cfg)
        
        # åˆ›å»ºä¼˜å…ˆçº§åå¥½é›†æˆå™¨
        try:
            prioritized_integrator = create_prioritized_preference_integrator(
                task_name=cfg.task,
                cfg=cfg,
                integration_config=integration_config,
                legacy_integrator=None,  # å¯ä»¥åç»­æ·»åŠ ä¼ ç»Ÿé›†æˆå™¨ä½œä¸ºå›é€€
                tdmpc2_agent=agent  # ä¼ é€’TD-MPC2 agent
            )
            print(colored("âœ… ä¼˜å…ˆçº§åå¥½é›†æˆå™¨åˆ›å»ºæˆåŠŸ", "magenta"))
        except Exception as e:
            print(colored(f"âš ï¸ åˆ›å»ºä¼˜å…ˆçº§åå¥½é›†æˆå™¨å¤±è´¥: {e}", "yellow"))
            prioritized_integrator = None
        
        trainer = trainer_cls(
            cfg=cfg,
            env=env,
            agent=agent,
            buffer=Buffer(cfg),
            logger=Logger(cfg)
        )
        
        # å°†ä¼˜å…ˆçº§é›†æˆå™¨æ³¨å…¥åˆ°è®­ç»ƒå™¨ä¸­
        if prioritized_integrator and hasattr(trainer, 'set_prioritized_integrator'):
            trainer.set_prioritized_integrator(prioritized_integrator)
            print(colored("âœ… ä¼˜å…ˆçº§é›†æˆå™¨å·²æ³¨å…¥è®­ç»ƒå™¨", "magenta"))
        elif prioritized_integrator:
            # å¦‚æœè®­ç»ƒå™¨æ²¡æœ‰ä¸“é—¨çš„æ–¹æ³•ï¼Œç›´æ¥è®¾ç½®å±æ€§
            trainer.prioritized_integrator = prioritized_integrator
            print(colored("âœ… ä¼˜å…ˆçº§é›†æˆå™¨å·²è®¾ç½®ä¸ºè®­ç»ƒå™¨å±æ€§", "magenta"))
        
        print(colored("âœ… ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ", "magenta", attrs=["bold"]))
        
    elif should_use_integrated_preference:
        # é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨ï¼ˆå•ä»»åŠ¡ï¼‰
        print(colored("åˆå§‹åŒ–é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨...", "green"))
        
        # å¯¼å…¥åå¥½æ„ŸçŸ¥TD-MPC2
        try:
            from prm.preference_aware_tdmpc2 import create_preference_aware_tdmpc2
            from prm.hybrid_value_estimator import HybridValueConfig
            
            # åˆ›å»ºåå¥½æ„ŸçŸ¥æ™ºèƒ½ä½“
            print(colored("åˆ›å»ºåå¥½æ„ŸçŸ¥TD-MPC2æ™ºèƒ½ä½“...", "cyan"))
            agent = create_preference_aware_tdmpc2(
                cfg=cfg,
                preference_integrator=None,  # åˆå§‹ä¸ºNoneï¼Œåç»­ç”±è®­ç»ƒå™¨ç®¡ç†
                preference_trainer=None,  # åˆå§‹ä¸ºNoneï¼Œåç»­ç”±è®­ç»ƒå™¨ç®¡ç†
                hybrid_config=HybridValueConfig.from_config(cfg),
                enable_preference_planning=True
            )
            print(colored("âœ… åå¥½æ„ŸçŸ¥TD-MPC2æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ", "cyan"))
            
        except ImportError as e:
            print(colored(f"âš ï¸ æ— æ³•å¯¼å…¥åå¥½æ„ŸçŸ¥TD-MPC2ï¼Œä½¿ç”¨æ ‡å‡†æ™ºèƒ½ä½“: {e}", "yellow"))
            agent = TDMPC2(cfg)
        
        trainer = trainer_cls(
            cfg=cfg,
            env=env,
            agent=agent,
            buffer=Buffer(cfg),
            logger=Logger(cfg)
        )
        print(colored("âœ… é›†æˆåå¥½å­¦ä¹ è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ", "green", attrs=["bold"]))
    else:
        # æ ‡å‡†åœ¨çº¿è®­ç»ƒå™¨ï¼ˆå•ä»»åŠ¡ï¼‰
        trainer = trainer_cls(
            cfg=cfg,
            env=env,
            agent=TDMPC2(cfg),
            buffer=Buffer(cfg),
            logger=Logger(cfg),
            use_preference_engine=use_preference_engine
        )

    # ä¸»è®­ç»ƒå¾ªç¯
    trainer.train()

    # è®­ç»ƒç»“æŸåçš„æ”¶å°¾
    trainer.logger.finish(trainer.agent)

    # æ‰“å°åå¥½ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    if should_use_prioritized_preference and hasattr(trainer, 'prioritized_integrator'):
        try:
            integrator = trainer.prioritized_integrator
            if integrator:
                stats = integrator.get_statistics()
                print(colored("\n=== ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯ ===", "magenta", attrs=["bold"]))
                print(colored(f"æ€»è®­ç»ƒå›åˆæ•°: {stats.get('total_episodes', 0)}", "magenta"))
                print(colored(f"ä¼˜å…ˆçº§è®­ç»ƒæ­¥æ•°: {stats.get('prioritized_training_steps', 0)}", "magenta"))
                print(colored(f"æ··åˆè®­ç»ƒæ­¥æ•°: {stats.get('hybrid_training_steps', 0)}", "magenta"))
                print(colored(f"å›é€€æ¬¡æ•°: {stats.get('fallback_count', 0)}", "yellow"))
                print(colored(f"é”™è¯¯æ¬¡æ•°: {stats.get('error_count', 0)}", "red" if stats.get('error_count', 0) > 0 else "green"))
                print(colored(f"æ€»è¿è¡Œæ—¶é—´: {stats.get('total_runtime_seconds', 0):.2f}ç§’", "cyan"))
                
                # é™é»˜å¤„ç†ä¼˜å…ˆçº§ç³»ç»Ÿå’Œæ€§èƒ½ç›‘æ§ç»Ÿè®¡ï¼Œä¸è¾“å‡ºè¯¦ç»†ä¿¡æ¯
                
                print(colored("=" * 40, "magenta"))
        except Exception as e:
            print(colored(f"è·å–ä¼˜å…ˆçº§åå¥½ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", "yellow"))
    
    elif should_use_integrated_preference and hasattr(trainer, 'get_preference_stats'):
        try:
            stats = trainer.get_preference_stats()
            print(colored("\n=== åå¥½å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯ ===", "cyan", attrs=["bold"]))
            print(colored(f"å†å²æ•°æ®æ”¶é›†æ¬¡æ•°: {stats.get('historical_data_collections', 0)}", "green"))
            print(colored(f"åå¥½æ¨¡å‹æ›´æ–°æ¬¡æ•°: {stats.get('preference_model_updates', 0)}", "green"))
            print(colored(f"ç¼“å­˜è½¨è¿¹æ•°: {stats.get('total_trajectories', 0)}", "green"))
            print(colored(f"ç¼“å­˜åå¥½å¯¹æ•°: {stats.get('total_preference_pairs', 0)}", "green"))
            print(colored(f"å†…å­˜ä½¿ç”¨: {stats.get('memory_usage_estimate', 'N/A')}", "green"))
            print(colored("=" * 30, "cyan"))
        except Exception as e:
            print(colored(f"è·å–åå¥½å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}", "yellow"))

    # æ‰“å°è®­ç»ƒå®Œæˆä¿¡æ¯
    print(colored("\nğŸ‰ Training completed successfully! ğŸ‰", "green", attrs=["bold"]))


# å¦‚æœæ­¤è„šæœ¬æ˜¯ä¸»ç¨‹åºï¼Œåˆ™è°ƒç”¨ train å‡½æ•°
if __name__ == "__main__":
    train()
