#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å•ä¸€åˆ¤æ–­é€»è¾‘ï¼šè¦æ±‚å…¶ä¸­ä¸€æ¡è½¨è¿¹å¿…é¡»é«˜äºå†å²æœ€é«˜45%é˜ˆå€¼
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

import numpy as np
import logging
from prm.adaptive_threshold_manager import AdaptiveThresholdManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def test_single_threshold_logic():
    """æµ‹è¯•å•ä¸€åˆ¤æ–­é€»è¾‘"""
    print("=== æµ‹è¯•å•ä¸€åˆ¤æ–­é€»è¾‘ï¼šè¦æ±‚å…¶ä¸­ä¸€æ¡è½¨è¿¹å¿…é¡»é«˜äºå†å²æœ€é«˜45%é˜ˆå€¼ ===")
    
    # åˆ›å»ºè‡ªé€‚åº”é˜ˆå€¼ç®¡ç†å™¨
    config = {
        'confidence_threshold': 0.7,
        'rule_score_diff_threshold': 8.0,
        'env_reward_diff_threshold': 2.0
    }
    manager = AdaptiveThresholdManager(config, window_size=30)
    
    # æ¨¡æ‹Ÿæ·»åŠ ä¸€äº›å¥–åŠ±æ ·æœ¬æ¥å»ºç«‹å†å²æœ€é«˜å€¼
    print("\n1. å»ºç«‹å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼...")
    rewards = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55]  # å†å²æœ€é«˜çª—å£å¹³å‡å€¼åº”è¯¥æ˜¯50
    for reward in rewards:
        manager.add_reward_sample(reward, reward * 0.8)
    
    # æ·»åŠ æ›´å¤šæ ·æœ¬ï¼ŒåŒ…æ‹¬ä¸€ä¸ªæ›´é«˜çš„çª—å£
    high_rewards = [60, 65, 70, 75, 80]  # è¿™ä¸ªçª—å£å¹³å‡å€¼åº”è¯¥æ˜¯70ï¼Œæˆä¸ºæ–°çš„å†å²æœ€é«˜
    for reward in high_rewards:
        manager.add_reward_sample(reward, reward * 0.8)
    
    # è·å–å†å²æœ€é«˜å€¼å’Œ45%é˜ˆå€¼
    historical_max = manager.get_historical_max_env_avg()
    threshold_45 = manager.get_historical_max_threshold(0.45)
    
    print(f"å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼: {historical_max:.3f}")
    print(f"å†å²æœ€é«˜45%é˜ˆå€¼: {threshold_45:.3f}")
    
    # æµ‹è¯•ä¸åŒçš„è½¨è¿¹å¯¹
    test_cases = [
        # (è½¨è¿¹Aå¥–åŠ±, è½¨è¿¹Bå¥–åŠ±, é¢„æœŸç»“æœ, æè¿°)
        (15, 18, False, "ä¸¤æ¡è½¨è¿¹éƒ½ä½äº45%é˜ˆå€¼"),
        (40, 30, True, "è½¨è¿¹Aé«˜äº45%é˜ˆå€¼"),
        (15, 35, True, "è½¨è¿¹Bé«˜äº45%é˜ˆå€¼"),
        (50, 60, True, "ä¸¤æ¡è½¨è¿¹éƒ½é«˜äº45%é˜ˆå€¼"),
        (10, 15, False, "ä¸¤æ¡è½¨è¿¹éƒ½è¿œä½äº45%é˜ˆå€¼"),
        (threshold_45 + 0.1, 15, True, "è½¨è¿¹Aåˆšå¥½é«˜äº45%é˜ˆå€¼"),
        (15, threshold_45 - 0.1, False, "è½¨è¿¹Båˆšå¥½ä½äº45%é˜ˆå€¼")
    ]
    
    print("\n2. æµ‹è¯•å•ä¸€åˆ¤æ–­é€»è¾‘...")
    passed_tests = 0
    total_tests = len(test_cases)
    
    for i, (reward_a, reward_b, expected, description) in enumerate(test_cases, 1):
        # å•ä¸€åˆ¤æ–­ï¼šè‡³å°‘æœ‰ä¸€æ¡è½¨è¿¹é«˜äºå†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çš„45%
        at_least_one_above_threshold = (reward_a >= threshold_45 or reward_b >= threshold_45)
        
        result = "é€šè¿‡" if at_least_one_above_threshold == expected else "å¤±è´¥"
        status = "âœ“" if at_least_one_above_threshold == expected else "âœ—"
        
        print(f"æµ‹è¯• {i}: {description}")
        print(f"  è½¨è¿¹Aå¥–åŠ±: {reward_a:.3f}, è½¨è¿¹Bå¥–åŠ±: {reward_b:.3f}")
        print(f"  åˆ¤æ–­ç»“æœ: {at_least_one_above_threshold}, é¢„æœŸ: {expected}")
        print(f"  {status} {result}")
        print()
        
        if at_least_one_above_threshold == expected:
            passed_tests += 1
    
    print(f"æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
    
    # æµ‹è¯•è¾¹ç•Œæƒ…å†µ
    print("\n3. æµ‹è¯•è¾¹ç•Œæƒ…å†µ...")
    
    # æµ‹è¯•å†å²æœ€é«˜å€¼æ›´æ–°
    print("æµ‹è¯•å†å²æœ€é«˜å€¼æ›´æ–°...")
    old_max = manager.get_historical_max_env_avg()
    
    # æ·»åŠ ä¸€ä¸ªæ›´é«˜çš„çª—å£
    super_high_rewards = [90, 95, 100, 105, 110]  # å¹³å‡å€¼100ï¼Œåº”è¯¥æˆä¸ºæ–°çš„å†å²æœ€é«˜
    for reward in super_high_rewards:
        manager.add_reward_sample(reward, reward * 0.8)
    
    new_max = manager.get_historical_max_env_avg()
    new_threshold_45 = manager.get_historical_max_threshold(0.45)
    
    print(f"æ—§å†å²æœ€é«˜å€¼: {old_max:.3f}")
    print(f"æ–°å†å²æœ€é«˜å€¼: {new_max:.3f}")
    print(f"æ–°45%é˜ˆå€¼: {new_threshold_45:.3f}")
    
    if new_max > old_max:
        print("âœ“ å†å²æœ€é«˜å€¼æ­£ç¡®æ›´æ–°")
    else:
        print("âœ— å†å²æœ€é«˜å€¼æ›´æ–°å¤±è´¥")
    
    return passed_tests == total_tests

def test_anti_garbage_data_logic():
    """æµ‹è¯•é˜²åƒåœ¾æ•°æ®é€»è¾‘"""
    print("\n=== æµ‹è¯•é˜²åƒåœ¾æ•°æ®é€»è¾‘ ===")
    
    config = {
        'confidence_threshold': 0.7,
        'rule_score_diff_threshold': 8.0,
        'env_reward_diff_threshold': 2.0
    }
    manager = AdaptiveThresholdManager(config, window_size=30)
    
    # å»ºç«‹ä¸€ä¸ªè¾ƒé«˜çš„å†å²æœ€é«˜å€¼
    high_quality_rewards = [80, 85, 90, 95, 100]
    for reward in high_quality_rewards:
        manager.add_reward_sample(reward, reward * 0.8)
    
    historical_max = manager.get_historical_max_env_avg()
    threshold_45 = manager.get_historical_max_threshold(0.45)
    
    print(f"å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼: {historical_max:.3f}")
    print(f"45%é˜ˆå€¼: {threshold_45:.3f}")
    
    # æµ‹è¯•åƒåœ¾æ•°æ®å¯¹
    garbage_pairs = [
        (5, 10, "ä½è´¨é‡ vs ä½è´¨é‡"),
        (15, 20, "ä¸­ä½è´¨é‡ vs ä¸­ä½è´¨é‡"),
        (25, 30, "ä¸­ç­‰è´¨é‡ vs ä¸­ç­‰è´¨é‡")
    ]
    
    print("\næµ‹è¯•åƒåœ¾æ•°æ®è¿‡æ»¤...")
    filtered_count = 0
    
    for reward_a, reward_b, description in garbage_pairs:
        at_least_one_above_threshold = (reward_a >= threshold_45 or reward_b >= threshold_45)
        
        if not at_least_one_above_threshold:
            print(f"âœ“ æˆåŠŸè¿‡æ»¤: {description} (A={reward_a}, B={reward_b})")
            filtered_count += 1
        else:
            print(f"âœ— è¿‡æ»¤å¤±è´¥: {description} (A={reward_a}, B={reward_b})")
    
    # æµ‹è¯•é«˜è´¨é‡æ•°æ®ä¿ç•™
    quality_pairs = [
        (threshold_45 + 5, 20, "é«˜è´¨é‡ vs ä½è´¨é‡"),
        (30, threshold_45 + 10, "ä¸­ç­‰è´¨é‡ vs é«˜è´¨é‡"),
        (threshold_45 + 5, threshold_45 + 10, "é«˜è´¨é‡ vs é«˜è´¨é‡")
    ]
    
    print("\næµ‹è¯•é«˜è´¨é‡æ•°æ®ä¿ç•™...")
    retained_count = 0
    
    for reward_a, reward_b, description in quality_pairs:
        at_least_one_above_threshold = (reward_a >= threshold_45 or reward_b >= threshold_45)
        
        if at_least_one_above_threshold:
            print(f"âœ“ æˆåŠŸä¿ç•™: {description} (A={reward_a:.1f}, B={reward_b:.1f})")
            retained_count += 1
        else:
            print(f"âœ— ä¿ç•™å¤±è´¥: {description} (A={reward_a:.1f}, B={reward_b:.1f})")
    
    print(f"\né˜²åƒåœ¾æ•°æ®æµ‹è¯•ç»“æœ:")
    print(f"  æˆåŠŸè¿‡æ»¤åƒåœ¾æ•°æ®: {filtered_count}/{len(garbage_pairs)}")
    print(f"  æˆåŠŸä¿ç•™é«˜è´¨é‡æ•°æ®: {retained_count}/{len(quality_pairs)}")
    
    return filtered_count == len(garbage_pairs) and retained_count == len(quality_pairs)

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•å•ä¸€åˆ¤æ–­é€»è¾‘...")
    
    # è¿è¡Œæµ‹è¯•
    test1_passed = test_single_threshold_logic()
    test2_passed = test_anti_garbage_data_logic()
    
    print("\n=== æ€»ä½“æµ‹è¯•ç»“æœ ===")
    print(f"å•ä¸€åˆ¤æ–­é€»è¾‘æµ‹è¯•: {'é€šè¿‡' if test1_passed else 'å¤±è´¥'}")
    print(f"é˜²åƒåœ¾æ•°æ®é€»è¾‘æµ‹è¯•: {'é€šè¿‡' if test2_passed else 'å¤±è´¥'}")
    
    if test1_passed and test2_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å•ä¸€åˆ¤æ–­é€»è¾‘å·¥ä½œæ­£å¸¸ã€‚")
        print("âœ… ç³»ç»Ÿç°åœ¨è¦æ±‚è‡³å°‘ä¸€æ¡è½¨è¿¹é«˜äºå†å²æœ€é«˜45%é˜ˆå€¼ï¼Œæœ‰æ•ˆé˜²æ­¢åƒåœ¾æ•°æ®å­¦ä¹ ã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°ã€‚")