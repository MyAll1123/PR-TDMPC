#!/usr/bin/env python3
"""
æµ‹è¯•å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çª—å£æœºåˆ¶å’ŒåŒé‡åˆ¤æ–­é€»è¾‘

è¿™ä¸ªè„šæœ¬æµ‹è¯•ï¼š
1. AdaptiveThresholdManagerä¸­å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çš„è·Ÿè¸ªå’Œæ›´æ–°
2. PrioritizedPreferenceSystemä¸­åŒé‡åˆ¤æ–­æœºåˆ¶çš„è¿‡æ»¤é€»è¾‘
3. è½¨è¿¹å¥–åŠ±æ•°æ®æ­£ç¡®ä¼ é€’ç»™AdaptiveThresholdManager
"""

import sys
import os
sys.path.append('/public/home/yaotianxiao2024/SPE')
sys.path.append('/public/home/yaotianxiao2024/SPE/prm')

import numpy as np
import logging
from typing import Dict, List

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_adaptive_threshold_manager():
    """æµ‹è¯•AdaptiveThresholdManagerçš„å†å²æœ€é«˜å€¼è·Ÿè¸ªåŠŸèƒ½"""
    print("\n=== æµ‹è¯•AdaptiveThresholdManagerå†å²æœ€é«˜å€¼è·Ÿè¸ª ===")
    
    try:
        from adaptive_threshold_manager import AdaptiveThresholdManager
        
        # åˆ›å»ºé…ç½®
        config = {
            'confidence_threshold': 0.75,
            'rule_score_diff_multiplier': 2.0,
            'env_reward_diff_std_multiplier': 1.5,
            'min_quality_indicators': 2
        }
        
        # åˆ›å»ºç®¡ç†å™¨ï¼Œçª—å£å¤§å°ä¸º5ï¼ˆä¾¿äºæµ‹è¯•ï¼‰
        manager = AdaptiveThresholdManager(config, window_size=5)
        
        print(f"åˆå§‹å†å²æœ€é«˜å€¼: {manager.get_historical_max_env_avg():.4f}")
        print(f"åˆå§‹å†å²æœ€é«˜30%é˜ˆå€¼: {manager.get_historical_max_threshold(0.3):.4f}")
        
        # æ¨¡æ‹Ÿæ·»åŠ å¥–åŠ±æ ·æœ¬
        test_rewards = [1.0, 2.0, 3.0, 4.0, 5.0]  # ç¬¬ä¸€ä¸ªçª—å£ï¼Œå¹³å‡å€¼3.0
        print("\næ·»åŠ ç¬¬ä¸€ä¸ªçª—å£çš„å¥–åŠ±æ ·æœ¬:")
        for i, reward in enumerate(test_rewards):
            manager.add_reward_sample(reward, reward * 0.1)  # rule_score = reward * 0.1
            print(f"  æ ·æœ¬{i+1}: å¥–åŠ±={reward:.1f}, å½“å‰å†å²æœ€é«˜={manager.get_historical_max_env_avg():.4f}")
        
        print(f"ç¬¬ä¸€ä¸ªçª—å£å®Œæˆåå†å²æœ€é«˜å€¼: {manager.get_historical_max_env_avg():.4f}")
        print(f"å†å²æœ€é«˜30%é˜ˆå€¼: {manager.get_historical_max_threshold(0.3):.4f}")
        
        # æ·»åŠ ç¬¬äºŒä¸ªçª—å£ï¼ˆæ›´é«˜çš„å¥–åŠ±ï¼‰
        test_rewards_2 = [6.0, 7.0, 8.0, 9.0, 10.0]  # ç¬¬äºŒä¸ªçª—å£ï¼Œå¹³å‡å€¼8.0
        print("\næ·»åŠ ç¬¬äºŒä¸ªçª—å£çš„å¥–åŠ±æ ·æœ¬ï¼ˆæ›´é«˜å¥–åŠ±ï¼‰:")
        for i, reward in enumerate(test_rewards_2):
            manager.add_reward_sample(reward, reward * 0.1)
            print(f"  æ ·æœ¬{i+1}: å¥–åŠ±={reward:.1f}, å½“å‰å†å²æœ€é«˜={manager.get_historical_max_env_avg():.4f}")
        
        print(f"ç¬¬äºŒä¸ªçª—å£å®Œæˆåå†å²æœ€é«˜å€¼: {manager.get_historical_max_env_avg():.4f}")
        print(f"å†å²æœ€é«˜30%é˜ˆå€¼: {manager.get_historical_max_threshold(0.3):.4f}")
        
        # æ·»åŠ ç¬¬ä¸‰ä¸ªçª—å£ï¼ˆè¾ƒä½çš„å¥–åŠ±ï¼Œä¸åº”æ›´æ–°å†å²æœ€é«˜å€¼ï¼‰
        test_rewards_3 = [2.0, 3.0, 4.0, 5.0, 6.0]  # ç¬¬ä¸‰ä¸ªçª—å£ï¼Œå¹³å‡å€¼4.0
        print("\næ·»åŠ ç¬¬ä¸‰ä¸ªçª—å£çš„å¥–åŠ±æ ·æœ¬ï¼ˆè¾ƒä½å¥–åŠ±ï¼‰:")
        for i, reward in enumerate(test_rewards_3):
            manager.add_reward_sample(reward, reward * 0.1)
            print(f"  æ ·æœ¬{i+1}: å¥–åŠ±={reward:.1f}, å½“å‰å†å²æœ€é«˜={manager.get_historical_max_env_avg():.4f}")
        
        print(f"ç¬¬ä¸‰ä¸ªçª—å£å®Œæˆåå†å²æœ€é«˜å€¼: {manager.get_historical_max_env_avg():.4f}")
        print(f"å†å²æœ€é«˜30%é˜ˆå€¼: {manager.get_historical_max_threshold(0.3):.4f}")
        
        # æµ‹è¯•é‡ç½®åŠŸèƒ½
        print("\næµ‹è¯•é‡ç½®åŠŸèƒ½:")
        manager.reset()
        print(f"é‡ç½®åå†å²æœ€é«˜å€¼: {manager.get_historical_max_env_avg():.4f}")
        print(f"é‡ç½®åå†å²æœ€é«˜30%é˜ˆå€¼: {manager.get_historical_max_threshold(0.3):.4f}")
        
        print("âœ… AdaptiveThresholdManagerå†å²æœ€é«˜å€¼è·Ÿè¸ªæµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ AdaptiveThresholdManageræµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_double_judgment_logic():
    """æµ‹è¯•åŒé‡åˆ¤æ–­é€»è¾‘çš„æ¨¡æ‹Ÿ"""
    print("\n=== æµ‹è¯•åŒé‡åˆ¤æ–­é€»è¾‘æ¨¡æ‹Ÿ ===")
    
    try:
        from adaptive_threshold_manager import AdaptiveThresholdManager
        
        # åˆ›å»ºé…ç½®
        config = {
            'confidence_threshold': 0.75,
            'rule_score_diff_multiplier': 2.0,
            'env_reward_diff_std_multiplier': 1.5,
            'min_quality_indicators': 2
        }
        
        # åˆ›å»ºç®¡ç†å™¨
        manager = AdaptiveThresholdManager(config, window_size=5)
        
        # å»ºç«‹å†å²æœ€é«˜å€¼
        high_rewards = [8.0, 9.0, 10.0, 11.0, 12.0]  # å¹³å‡å€¼10.0
        for reward in high_rewards:
            manager.add_reward_sample(reward)
        
        historical_max = manager.get_historical_max_env_avg()
        historical_threshold = manager.get_historical_max_threshold(0.3)
        
        print(f"å»ºç«‹çš„å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼: {historical_max:.4f}")
        print(f"å†å²æœ€é«˜30%é˜ˆå€¼: {historical_threshold:.4f}")
        
        # æ¨¡æ‹Ÿå½“å‰çª—å£
        current_rewards = [4.0, 5.0, 6.0, 7.0, 8.0]  # å¹³å‡å€¼6.0
        for reward in current_rewards:
            manager.add_reward_sample(reward)
        
        stats = manager.get_statistics_summary()
        current_avg = stats.get('mean', 0.0)
        
        print(f"å½“å‰æ»‘åŠ¨å¹³å‡å€¼: {current_avg:.4f}")
        
        # æµ‹è¯•ä¸åŒè½¨è¿¹å¯¹çš„åŒé‡åˆ¤æ–­
        test_cases = [
            (7.0, 5.0, "è½¨è¿¹Aé«˜äºå½“å‰å¹³å‡ï¼Œè½¨è¿¹Bé«˜äºå†å²é˜ˆå€¼"),
            (5.0, 4.0, "ä¸¤æ¡è½¨è¿¹éƒ½é«˜äºå†å²é˜ˆå€¼ï¼Œä½†éƒ½ä½äºå½“å‰å¹³å‡"),
            (8.0, 7.0, "ä¸¤æ¡è½¨è¿¹éƒ½é«˜äºå½“å‰å¹³å‡å’Œå†å²é˜ˆå€¼"),
            (2.0, 1.0, "ä¸¤æ¡è½¨è¿¹éƒ½ä½äºå†å²é˜ˆå€¼"),
            (7.0, 2.0, "è½¨è¿¹Aé«˜äºå½“å‰å¹³å‡å’Œå†å²é˜ˆå€¼ï¼Œè½¨è¿¹Bä½äºå†å²é˜ˆå€¼")
        ]
        
        print("\nåŒé‡åˆ¤æ–­æµ‹è¯•ç»“æœ:")
        for reward_a, reward_b, description in test_cases:
            # ç¬¬ä¸€é‡åˆ¤æ–­ï¼šè‡³å°‘æœ‰ä¸€æ¡è½¨è¿¹é«˜äºå½“å‰æ»‘åŠ¨å¹³å‡å€¼
            at_least_one_above_current = (reward_a >= current_avg or reward_b >= current_avg)
            
            # ç¬¬äºŒé‡åˆ¤æ–­ï¼šä¸¤æ¡è½¨è¿¹éƒ½è¦é«˜äºå†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çš„30%
            both_above_historical = (reward_a >= historical_threshold and reward_b >= historical_threshold)
            
            # æœ€ç»ˆåˆ¤æ–­
            pass_filter = at_least_one_above_current and both_above_historical
            
            status = "âœ… é€šè¿‡" if pass_filter else "âŒ è¿‡æ»¤"
            print(f"  {description}")
            print(f"    è½¨è¿¹A: {reward_a:.1f}, è½¨è¿¹B: {reward_b:.1f}")
            print(f"    ç¬¬ä¸€é‡åˆ¤æ–­: {at_least_one_above_current} (è‡³å°‘ä¸€æ¡ >= {current_avg:.1f})")
            print(f"    ç¬¬äºŒé‡åˆ¤æ–­: {both_above_historical} (ä¸¤æ¡éƒ½ >= {historical_threshold:.1f})")
            print(f"    ç»“æœ: {status}")
            print()
        
        print("âœ… åŒé‡åˆ¤æ–­é€»è¾‘æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ åŒé‡åˆ¤æ–­é€»è¾‘æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_integration():
    """æµ‹è¯•é›†æˆåŠŸèƒ½"""
    print("\n=== æµ‹è¯•é›†æˆåŠŸèƒ½ ===")
    
    try:
        # æµ‹è¯•å¯¼å…¥
        from prioritized_preference_system import PrioritizedPreferenceSystem, PrioritizedSystemConfig
        from adaptive_threshold_manager import AdaptiveThresholdManager
        
        print("âœ… æˆåŠŸå¯¼å…¥ç›¸å…³æ¨¡å—")
        
        # æµ‹è¯•é…ç½®åˆ›å»º
        config = PrioritizedSystemConfig()
        print(f"âœ… æˆåŠŸåˆ›å»ºé…ç½®ï¼Œçª—å£å¤§å°: {getattr(config, 'window_size', 'æœªè®¾ç½®')}")
        
        # æµ‹è¯•AdaptiveThresholdManageråˆ›å»º
        threshold_config = {
            'confidence_threshold': 0.75,
            'rule_score_diff_multiplier': 2.0,
            'env_reward_diff_std_multiplier': 1.5,
            'min_quality_indicators': 2
        }
        
        manager = AdaptiveThresholdManager(threshold_config, window_size=30)
        print("âœ… æˆåŠŸåˆ›å»ºAdaptiveThresholdManager")
        
        # æµ‹è¯•æ–°å¢æ–¹æ³•
        historical_max = manager.get_historical_max_env_avg()
        historical_threshold = manager.get_historical_max_threshold(0.3)
        print(f"âœ… å†å²æœ€é«˜å€¼æ–¹æ³•æ­£å¸¸: {historical_max:.4f}, 30%é˜ˆå€¼: {historical_threshold:.4f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çª—å£æœºåˆ¶å’ŒåŒé‡åˆ¤æ–­é€»è¾‘")
    print("=" * 60)
    
    results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    results.append(test_adaptive_threshold_manager())
    results.append(test_double_judgment_logic())
    results.append(test_integration())
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    test_names = [
        "AdaptiveThresholdManagerå†å²æœ€é«˜å€¼è·Ÿè¸ª",
        "åŒé‡åˆ¤æ–­é€»è¾‘æ¨¡æ‹Ÿ",
        "é›†æˆåŠŸèƒ½æµ‹è¯•"
    ]
    
    passed = 0
    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{i+1}. {name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å†å²æœ€é«˜ç¯å¢ƒå¹³å‡å€¼çª—å£æœºåˆ¶å’ŒåŒé‡åˆ¤æ–­é€»è¾‘å®ç°æ­£ç¡®ã€‚")
        return True
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)