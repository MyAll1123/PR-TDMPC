#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ–°çš„è´¨é‡åˆ†æ•°è®¡ç®—å…¬å¼
éªŒè¯ï¼šæœ€ç»ˆåˆ†æ•° = ç¯å¢ƒå¥–åŠ± Ã— åŸºç¡€è´¨é‡å› å­ Ã— (1 + APIè§„åˆ™è´¡çŒ®)
å…¶ä¸­APIè§„åˆ™è´¡çŒ®èŒƒå›´ä¸º (-0.3, 0.3)
"""

import sys
import os
sys.path.append('/public/home/yaotianxiao2024/SPE')
sys.path.append('/public/home/yaotianxiao2024/SPE/prm')

import numpy as np
import torch
from preference_labeling_engine import PreferenceLabelingEngine, TrajectoryQualityEvaluator
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_test_trajectory(length=100, task_type='walk'):
    """
    åˆ›å»ºæµ‹è¯•è½¨è¿¹æ•°æ®
    """
    if task_type == 'walk':
        # æ¨¡æ‹Ÿè¡Œèµ°ä»»åŠ¡çš„è§‚æµ‹å’ŒåŠ¨ä½œ
        obs_dim = 45  # H1æœºå™¨äººè§‚æµ‹ç»´åº¦
        act_dim = 19  # H1æœºå™¨äººåŠ¨ä½œç»´åº¦
        
        # ç”Ÿæˆç¨³å®šçš„è¡Œèµ°è½¨è¿¹
        obs_seq = np.random.randn(length, obs_dim) * 0.1
        obs_seq[:, :3] += np.array([0, 0, 1.0])  # ä¿æŒç«™ç«‹é«˜åº¦
        
        act_seq = np.random.randn(length, act_dim) * 0.05  # å°å¹…åŠ¨ä½œå˜åŒ–
        
        # æ¨¡æ‹Ÿç¯å¢ƒå¥–åŠ±ï¼ˆè¡Œèµ°ä»»åŠ¡é€šå¸¸åŸºäºå‰è¿›é€Ÿåº¦ï¼‰
        env_rewards = np.random.uniform(0.5, 2.0, length)  # æ­£å‘å¥–åŠ±
        
    elif task_type == 'balance':
        # æ¨¡æ‹Ÿå¹³è¡¡ä»»åŠ¡
        obs_dim = 45
        act_dim = 19
        
        # ç”Ÿæˆå¹³è¡¡è½¨è¿¹ï¼ˆè¾ƒå°çš„çŠ¶æ€å˜åŒ–ï¼‰
        obs_seq = np.random.randn(length, obs_dim) * 0.05
        obs_seq[:, :3] += np.array([0, 0, 1.0])  # ä¿æŒç«™ç«‹é«˜åº¦
        
        act_seq = np.random.randn(length, act_dim) * 0.02  # æ›´å°çš„åŠ¨ä½œ
        
        # å¹³è¡¡ä»»åŠ¡å¥–åŠ±è¾ƒä½ä½†ç¨³å®š
        env_rewards = np.random.uniform(0.1, 0.8, length)
        
    else:
        # é»˜è®¤è½¨è¿¹
        obs_dim = 45
        act_dim = 19
        obs_seq = np.random.randn(length, obs_dim) * 0.1
        act_seq = np.random.randn(length, act_dim) * 0.1
        env_rewards = np.random.uniform(0.0, 1.0, length)
    
    return obs_seq, act_seq, env_rewards

def test_quality_formula():
    """
    æµ‹è¯•æ–°çš„è´¨é‡åˆ†æ•°è®¡ç®—å…¬å¼
    """
    print("\n" + "="*80)
    print("ğŸ§ª æµ‹è¯•æ–°çš„è´¨é‡åˆ†æ•°è®¡ç®—å…¬å¼")
    print("="*80)
    
    # åˆ›å»ºè´¨é‡è¯„ä¼°å™¨
    evaluator = TrajectoryQualityEvaluator('h1hand-walk-v0')
    
    # åˆ›å»ºæµ‹è¯•è½¨è¿¹
    obs_seq, act_seq, env_rewards = create_test_trajectory(100, 'walk')
    
    print(f"\nğŸ“Š æµ‹è¯•è½¨è¿¹ä¿¡æ¯:")
    print(f"   è½¨è¿¹é•¿åº¦: {len(obs_seq)}")
    print(f"   è§‚æµ‹ç»´åº¦: {obs_seq.shape[1]}")
    print(f"   åŠ¨ä½œç»´åº¦: {act_seq.shape[1]}")
    print(f"   ç¯å¢ƒå¥–åŠ±èŒƒå›´: [{env_rewards.min():.3f}, {env_rewards.max():.3f}]")
    print(f"   ç¯å¢ƒå¥–åŠ±æ€»å’Œ: {env_rewards.sum():.3f}")
    
    # è½¬æ¢ä¸ºtorchå¼ é‡
    obs_tensor = torch.FloatTensor(obs_seq)
    act_tensor = torch.FloatTensor(act_seq)
    env_rewards_tensor = torch.FloatTensor(env_rewards)
    
    # è¯„ä¼°è½¨è¿¹è´¨é‡
    try:
        quality_score, detailed_scores = evaluator.evaluate_trajectory_quality(
            obs_tensor, act_tensor, env_rewards_tensor
        )
        
        print(f"\nğŸ¯ è´¨é‡è¯„ä¼°ç»“æœ:")
        print(f"   æ€»è´¨é‡åˆ†æ•°: {quality_score:.6f}")
        
        # æ˜¾ç¤ºè¯¦ç»†åˆ†æ•°
        print(f"\nğŸ“‹ è¯¦ç»†åˆ†æ•°ç»„æˆ:")
        for key, value in detailed_scores.items():
            if isinstance(value, (int, float)):
                print(f"   {key}: {value:.6f}")
        
        # åˆ†ææ–°å…¬å¼çš„ç»„æˆéƒ¨åˆ†
        if 'api_contribution' in detailed_scores:
            api_contrib = detailed_scores['api_contribution']
            env_reward_sum = env_rewards.sum()
            
            # è®¡ç®—åŸºç¡€è´¨é‡å› å­ï¼ˆä»è¯¦ç»†åˆ†æ•°ä¸­æ¨å¯¼ï¼‰
            survival_score = detailed_scores.get('survival_time', 1.0)
            stability_score = detailed_scores.get('state_stability', 1.0)
            smoothness_score = detailed_scores.get('action_smoothness', 1.0)
            base_quality_factor = survival_score * stability_score * smoothness_score
            
            print(f"\nğŸ” æ–°å…¬å¼åˆ†æ:")
            print(f"   ç¯å¢ƒå¥–åŠ±æ€»å’Œ: {env_reward_sum:.6f}")
            print(f"   åŸºç¡€è´¨é‡å› å­: {base_quality_factor:.6f}")
            print(f"   APIè§„åˆ™è´¡çŒ®: {api_contrib:.6f}")
            print(f"   APIè´¡çŒ®èŒƒå›´æ£€æŸ¥: {'âœ…' if -0.3 <= api_contrib <= 0.3 else 'âŒ'}")
            
            # éªŒè¯æ–°å…¬å¼
            expected_score = env_reward_sum * base_quality_factor * (1 + api_contrib)
            print(f"   é¢„æœŸåˆ†æ•°: {expected_score:.6f}")
            print(f"   å®é™…åˆ†æ•°: {quality_score:.6f}")
            print(f"   å…¬å¼éªŒè¯: {'âœ…' if abs(expected_score - quality_score) < 1e-6 else 'âŒ'}")
        
        return True, quality_score, detailed_scores
        
    except Exception as e:
        print(f"âŒ è´¨é‡è¯„ä¼°å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False, 0.0, {}

def test_api_contribution_range():
    """
    æµ‹è¯•APIè§„åˆ™è´¡çŒ®çš„èŒƒå›´é™åˆ¶
    """
    print("\n" + "="*80)
    print("ğŸ¯ æµ‹è¯•APIè§„åˆ™è´¡çŒ®èŒƒå›´é™åˆ¶")
    print("="*80)
    
    # åˆ›å»ºåå¥½æ ‡æ³¨å¼•æ“
    engine = PreferenceLabelingEngine('h1hand-walk-v0')
    
    # æµ‹è¯•å¤šä¸ªä¸åŒçš„è½¨è¿¹
    test_cases = [
        ('ä¼˜ç§€è½¨è¿¹', 'walk', 150),
        ('æ™®é€šè½¨è¿¹', 'walk', 100),
        ('è¾ƒå·®è½¨è¿¹', 'balance', 50),
    ]
    
    api_contributions = []
    
    for case_name, task_type, length in test_cases:
        print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹: {case_name}")
        
        # åˆ›å»ºæµ‹è¯•è½¨è¿¹
        obs_seq, act_seq, env_rewards = create_test_trajectory(length, task_type)
        
        try:
            # ç›´æ¥è°ƒç”¨APIè§„åˆ™æ–¹æ³•
            if hasattr(engine, '_apply_api_rules'):
                # æ„å»ºç‰¹å¾åˆ†æ•°ï¼ˆæ¨¡æ‹Ÿï¼‰
                feature_scores = {
                    'survival_time': length / 100.0,
                    'action_smoothness': np.random.uniform(0.7, 1.0),
                    'state_stability': np.random.uniform(0.6, 1.0),
                }
                
                api_contrib = engine._apply_api_rules(obs_seq, act_seq, feature_scores, {})
                api_contributions.append(api_contrib)
                
                print(f"   APIè§„åˆ™è´¡çŒ®: {api_contrib:.6f}")
                print(f"   èŒƒå›´æ£€æŸ¥: {'âœ…' if -0.3 <= api_contrib <= 0.3 else 'âŒ'}")
            else:
                print(f"   âŒ æœªæ‰¾åˆ°_apply_api_rulesæ–¹æ³•")
                
        except Exception as e:
            print(f"   âŒ APIè§„åˆ™è®¡ç®—å¤±è´¥: {e}")
    
    # ç»Ÿè®¡åˆ†æ
    if api_contributions:
        print(f"\nğŸ“Š APIè´¡çŒ®ç»Ÿè®¡åˆ†æ:")
        print(f"   æµ‹è¯•æ ·æœ¬æ•°: {len(api_contributions)}")
        print(f"   æœ€å°å€¼: {min(api_contributions):.6f}")
        print(f"   æœ€å¤§å€¼: {max(api_contributions):.6f}")
        print(f"   å¹³å‡å€¼: {np.mean(api_contributions):.6f}")
        print(f"   æ ‡å‡†å·®: {np.std(api_contributions):.6f}")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å€¼éƒ½åœ¨èŒƒå›´å†…
        in_range = all(-0.3 <= contrib <= 0.3 for contrib in api_contributions)
        print(f"   èŒƒå›´åˆè§„æ€§: {'âœ… å…¨éƒ¨åˆè§„' if in_range else 'âŒ å­˜åœ¨è¶…èŒƒå›´å€¼'}")
    
    return api_contributions

def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ–°çš„è´¨é‡åˆ†æ•°è®¡ç®—å…¬å¼")
    
    # æµ‹è¯•1: è´¨é‡åˆ†æ•°å…¬å¼
    success, score, details = test_quality_formula()
    
    if success:
        print(f"\nâœ… è´¨é‡åˆ†æ•°å…¬å¼æµ‹è¯•é€šè¿‡")
    else:
        print(f"\nâŒ è´¨é‡åˆ†æ•°å…¬å¼æµ‹è¯•å¤±è´¥")
        return
    
    # æµ‹è¯•2: APIè´¡çŒ®èŒƒå›´
    api_contribs = test_api_contribution_range()
    
    print(f"\n" + "="*80)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
    print("="*80)
    print(f"âœ… æ–°çš„è´¨é‡åˆ†æ•°å…¬å¼å·²å®ç°")
    print(f"âœ… APIè§„åˆ™è´¡çŒ®èŒƒå›´é™åˆ¶å·²ç”Ÿæ•ˆ")
    print(f"âœ… å…¬å¼éªŒè¯: æœ€ç»ˆåˆ†æ•° = ç¯å¢ƒå¥–åŠ± Ã— åŸºç¡€è´¨é‡å› å­ Ã— (1 + APIè§„åˆ™è´¡çŒ®)")
    print(f"âœ… APIè´¡çŒ®èŒƒå›´: (-0.3, 0.3)")
    
if __name__ == "__main__":
    main()